{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsst.sims.speedObservatory import Speed_observatory\n",
    "import lsst.sims.featureScheduler as fs\n",
    "import numpy as np\n",
    "import time\n",
    "import healpy as hp\n",
    "t0 = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "survey_length = 1.\n",
    "years = np.round(survey_length/365.25)\n",
    "nside = fs.set_default_nside(nside=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_slair_scheduler():\n",
    "    nside = fs.set_default_nside(nside=32)\n",
    "    # get rid of silly northern strip.\n",
    "    target_map = fs.standard_goals(nside=nside)\n",
    "    norm_factor = fs.calc_norm_factor(target_map)\n",
    "    # List to hold all the surveys (for easy plotting later)\n",
    "    surveys = []\n",
    "\n",
    "    # Set up observations to be taken in blocks\n",
    "    filter1s = ['u', 'g', 'r', 'i', 'z', 'y']\n",
    "    filter2s = [None, 'g', 'r', 'i', None, None]\n",
    "    pair_surveys = []\n",
    "    for filtername, filtername2 in zip(filter1s, filter2s):\n",
    "        bfs = []\n",
    "        bfs.append(fs.M5_diff_basis_function(filtername=filtername, nside=nside))\n",
    "        if filtername2 is not None:\n",
    "            bfs.append(fs.M5_diff_basis_function(filtername=filtername2, nside=nside))\n",
    "        bfs.append(fs.Target_map_basis_function(filtername=filtername,\n",
    "                                                target_map=target_map[filtername],\n",
    "                                                out_of_bounds_val=hp.UNSEEN, nside=nside,\n",
    "                                                norm_factor=norm_factor))\n",
    "        if filtername2 is not None:\n",
    "            bfs.append(fs.Target_map_basis_function(filtername=filtername2,\n",
    "                                                    target_map=target_map[filtername2],\n",
    "                                                    out_of_bounds_val=hp.UNSEEN, nside=nside,\n",
    "                                                    norm_factor=norm_factor))\n",
    "        bfs.append(fs.Slewtime_basis_function(filtername=filtername, nside=nside))\n",
    "        bfs.append(fs.Strict_filter_basis_function(filtername=filtername))\n",
    "        bfs.append(fs.Zenith_shadow_mask_basis_function(nside=nside, shadow_minutes=60., max_alt=76.))\n",
    "        weights = np.array([3.0, 3.0, .3, .3, 3., 3., 0.])\n",
    "        if filtername2 is None:\n",
    "            # Need to scale weights up so filter balancing still works properly.\n",
    "            weights = np.array([6.0, 0.6, 3., 3., 0.])\n",
    "        # XXX-\n",
    "        # This is where we could add a look-ahead basis function to include m5_diff in the future.\n",
    "        # Actually, having a near-future m5 would also help prevent switching to u or g right at twilight?\n",
    "        # Maybe just need a \"filter future\" basis function?\n",
    "        if filtername2 is None:\n",
    "            survey_name = 'blob, %s' % filtername\n",
    "        else:\n",
    "            survey_name = 'blob, %s%s' % (filtername, filtername2)\n",
    "        surveys.append(fs.Blob_survey(bfs, weights, filtername=filtername, filter2=filtername2,\n",
    "                                      survey_note=survey_name))\n",
    "        pair_surveys.append(surveys[-1])\n",
    "\n",
    "\n",
    "    # Let's set up some standard surveys as well to fill in the gaps. This is my old silly masked version.\n",
    "    # It would be good to put in Tiago's verion and lift nearly all the masking. That way this can also\n",
    "    # chase sucker holes.\n",
    "    filters = ['u', 'g', 'r', 'i', 'z', 'y']\n",
    "    #filters = ['i', 'z', 'y']\n",
    "    greedy_surveys = []\n",
    "    for filtername in filters:\n",
    "        bfs = []\n",
    "        bfs.append(fs.M5_diff_basis_function(filtername=filtername, nside=nside))\n",
    "        bfs.append(fs.Target_map_basis_function(filtername=filtername,\n",
    "                                                target_map=target_map[filtername],\n",
    "                                                out_of_bounds_val=hp.UNSEEN, nside=nside,\n",
    "                                                norm_factor=norm_factor))\n",
    "\n",
    "        bfs.append(fs.North_south_patch_basis_function(zenith_min_alt=50., nside=nside))\n",
    "        bfs.append(fs.Slewtime_basis_function(filtername=filtername, nside=nside))\n",
    "        bfs.append(fs.Strict_filter_basis_function(filtername=filtername))\n",
    "        bfs.append(fs.Zenith_shadow_mask_basis_function(nside=nside, shadow_minutes=60., max_alt=76.))\n",
    "        weights = np.array([3.0, 0.3, 1., 3., 3., 0.])\n",
    "        # Might want to try ignoring DD observations here, so the DD area gets covered normally--DONE\n",
    "        surveys.append(fs.Greedy_survey_fields(bfs, weights, block_size=1, filtername=filtername,\n",
    "                                               dither=True, nside=nside, ignore_obs='DD'))\n",
    "        greedy_surveys.append(surveys[-1])\n",
    "\n",
    "    # Set up the DD surveys\n",
    "    dd_surveys = fs.generate_dd_surveys()\n",
    "    surveys.extend(dd_surveys)\n",
    "\n",
    "    survey_list_o_lists = [dd_surveys, pair_surveys, greedy_surveys]\n",
    "\n",
    "    # put in as list-of-lists so pairs get evaluated first.\n",
    "    scheduler = fs.Core_scheduler(survey_list_o_lists, nside=nside)\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = generate_slair_scheduler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: ErfaWarning: ERFA function \"d2dtf\" yielded 1 of \"dubious year (Note 5)\" [astropy._erfa.core]\n",
      "/home/opsim/repos/sims_seeingModel/python/lsst/sims/seeingModel/seeingModel.py:73: Warning: Cannot calculate effective wavelengths; either sims_photUtils is unavailable (setup sims_photUtils) or $LSST_THROUGHPUTS_DEFAULT is undefined (setup throughputs package). Without these, simply using default effective wavelengths from version 1.3.\n",
      "  % (DEFAULT_WAVELENGTH_VERSION), Warning)\n"
     ]
    }
   ],
   "source": [
    "observatory = Speed_observatory(nside=nside, quickTest=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/opsim/repos/sims_seeingModel/python/lsst/sims/seeingModel/seeingModel.py:133: RuntimeWarning: invalid value encountered in power\n",
      "  airmass_correction = np.power(airmass, 0.6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress = 100.7%Skipped 0 observations\n",
      "Completed 645 observations\n"
     ]
    }
   ],
   "source": [
    "observatory, scheduler, observations = fs.sim_runner(observatory, scheduler,\n",
    "                                                     survey_length=survey_length,\n",
    "                                                     filename='blobs_same_zmask%iyrs.db' % years,\n",
    "                                                     delete_past=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ran in 79, 1 minutes=0 hours\n"
     ]
    }
   ],
   "source": [
    "trun = time.time() - t0\n",
    "print('ran in %i, %i minutes=%i hours' % (trun, trun/60., trun/3600.))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
